{"block_size": 512, "batch_size": 12, "split_ratio": 0.8, "steps": 100000, "max_tokens": 1024, "learning_rate": 0.0003, "n_embedd": 256, "attention_head_size": 256, "dropout": 0.2, "num_layers": 12, "num_heads": 4, "tokenizer_type": "tiktoken", "tokenizer_encoding": "cl100k_base", "vocab_size": 100256, "positional_encoder_type": "naive"}